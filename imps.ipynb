{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd50ae8",
   "metadata": {},
   "source": [
    "I'll explain the model code in detail. Let me first read the main training file to give you a comprehensive explanation. \n",
    "\n",
    "Read [](file:///Users/aksha/Desktop/medical-image-classifier-main/src/model_training.py)\n",
    "\n",
    "# üìö Detailed Explanation of the Medical Image Classifier Model\n",
    "\n",
    "Let me break down this code into digestible sections:\n",
    "\n",
    "## 1Ô∏è‚É£ **Overall Architecture Overview**\n",
    "\n",
    "This is a **Convolutional Neural Network (CNN)** trained to classify chest X-ray images into two categories:\n",
    "- **Normal** (healthy lungs) - labeled as `0`\n",
    "- **Pneumonia** (infected lungs) - labeled as `1`\n",
    "\n",
    "The model uses **TensorFlow/Keras**, which makes it easy to build and train deep learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ **Class: MedicalImageClassifier**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalImageClassifier:\n",
    "    def __init__(self, img_height=224, img_width=224):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0a731",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Purpose**: Wraps the entire training pipeline into organized methods.\n",
    "\n",
    "**Parameters**:\n",
    "- `img_height=224`: All images are resized to **224√ó224 pixels** (standard for deep learning)\n",
    "- `img_width=224`: Width of the image\n",
    "- `self.model`: Stores the neural network\n",
    "- `self.history`: Stores training history (loss & accuracy per epoch)\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ **Model Architecture: `create_model()` Method**\n",
    "\n",
    "This is the **heart of the model**. Let me explain each layer:\n",
    "\n",
    "### üìä **Input Layer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eb4f0",
   "metadata": {},
   "source": [
    "- Takes **224√ó224 RGB images** (3 color channels: Red, Green, Blue)\n",
    "\n",
    "### üîµ **Convolutional Block 1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "layers.BatchNormalization()\n",
    "layers.MaxPooling2D((2, 2))\n",
    "layers.Dropout(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371b52c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Conv2D (32 filters, 3√ó3 kernel)**:\n",
    "- Scans the image with **32 different filters** (like pattern detectors)\n",
    "- Each filter is a small **3√ó3 grid** that slides across the image\n",
    "- `padding='same'` keeps image dimensions the same\n",
    "- **ReLU activation**: Converts negative values to 0 (adds non-linearity)\n",
    "\n",
    "**Why filters?** Each filter learns to detect different features:\n",
    "- Filter 1 might detect **edges**\n",
    "- Filter 2 might detect **textures**\n",
    "- Filter 3 might detect **blurs**, etc.\n",
    "\n",
    "**BatchNormalization**:\n",
    "- Normalizes the output of each layer\n",
    "- Makes training **faster and more stable**\n",
    "- Helps prevent **internal covariate shift**\n",
    "\n",
    "**MaxPooling2D (2√ó2)**:\n",
    "- Reduces image size by taking the **maximum value** in each 2√ó2 window\n",
    "- Reduces computation and helps detect features at different scales\n",
    "- **224√ó224 ‚Üí 112√ó112**\n",
    "\n",
    "**Dropout(0.25)**:\n",
    "- Randomly \"turns off\" 25% of neurons during training\n",
    "- Prevents **overfitting** (memorizing the data instead of learning patterns)\n",
    "- Acts as regularization\n",
    "\n",
    "### üü° **Convolutional Block 2** (Same pattern, deeper features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D(64, (3, 3), activation='relu', padding='same')\n",
    "layers.BatchNormalization()\n",
    "layers.MaxPooling2D((2, 2))\n",
    "layers.Dropout(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f506e3",
   "metadata": {},
   "source": [
    "- **64 filters** (more than Block 1 for more complex features)\n",
    "- Image size: **112√ó112 ‚Üí 56√ó56**\n",
    "- Learns **second-level features** (combinations of first-level features)\n",
    "\n",
    "### üî¥ **Convolutional Block 3** (Highest-level features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D(128, (3, 3), activation='relu', padding='same')\n",
    "layers.BatchNormalization()\n",
    "layers.MaxPooling2D((2, 2))\n",
    "layers.Dropout(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc230713",
   "metadata": {},
   "source": [
    "- **128 filters** (most complex patterns)\n",
    "- Image size: **56√ó56 ‚Üí 28√ó28**\n",
    "- Learns **high-level medical patterns** (e.g., pneumonia patterns)\n",
    "\n",
    "**Why 3 blocks?**\n",
    "1. First block: **Low-level features** (edges, gradients)\n",
    "2. Second block: **Mid-level features** (shapes, textures)\n",
    "3. Third block: **High-level features** (medical patterns, anomalies)\n",
    "\n",
    "### üü£ **Classification Head** (Makes the final decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370fbb8",
   "metadata": {},
   "source": [
    "- Takes the 28√ó28√ó128 feature maps and **averages** them into a single value per filter\n",
    "- Results in **128 values** (one per filter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec050de",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Dense(256, activation='relu')\n",
    "layers.BatchNormalization()\n",
    "layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030db298",
   "metadata": {},
   "source": [
    "- **Dense layer**: Fully connected layer with 256 neurons\n",
    "- Learns **complex combinations** of features\n",
    "- **Dropout(0.5)**: Drop 50% (more aggressive, important for the final layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Dense(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035c1b6",
   "metadata": {},
   "source": [
    "- **Final output**: 1 neuron with **sigmoid activation**\n",
    "- Output range: **0 to 1**\n",
    "- **0 = Normal**, **1 = Pneumonia**\n",
    "- **Sigmoid**: Squashes values between 0-1 (probability-like)\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ **Model Compilation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74250c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616fb8f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Optimizer: Adam (learning_rate=0.001)**:\n",
    "- **Adam** = Adaptive Moment Estimation\n",
    "- Adjusts the learning rate automatically\n",
    "- Learning rate 0.001 means small, controlled weight updates\n",
    "- Too high = model diverges; Too low = slow training\n",
    "\n",
    "**Loss: Binary Crossentropy**:\n",
    "- Measures how far predictions are from ground truth\n",
    "- For binary classification (2 classes only)\n",
    "- Formula: `-(y*log(p) + (1-y)*log(1-p))`\n",
    "- Model tries to **minimize this loss**\n",
    "\n",
    "**Metrics: Accuracy**:\n",
    "- Percentage of correct predictions\n",
    "- **Accuracy = (TP + TN) / Total**\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ **Data Loading: `load_real_data()` Method**\n",
    "\n",
    "### üìÇ **Directory Structure Expected**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ffa82",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "data/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/     (1341 images)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/  (~3500 images)\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/     (8 images)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/  (8 images)\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îú‚îÄ‚îÄ NORMAL/     (100 images)\n",
    "    ‚îî‚îÄ‚îÄ PNEUMONIA/  (100 images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f25b72",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üñºÔ∏è **Image Processing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf092451",
   "metadata": {},
   "source": [
    "1. **Read** image using OpenCV\n",
    "2. **Convert** from BGR (OpenCV format) to RGB\n",
    "3. **Resize** to 224√ó224\n",
    "\n",
    "### üî¢ **Normalization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176737f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_normal_imgs + train_pneumonia_imgs, dtype=np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154776a",
   "metadata": {},
   "source": [
    "- Divides pixel values by 255\n",
    "- Converts range from **[0, 255] ‚Üí [0, 1]**\n",
    "- **Why?** Neural networks work better with normalized inputs\n",
    "\n",
    "### üîÄ **Shuffling**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train))\n",
    "X_train = X_train[shuffle_idx]\n",
    "y_train = y_train[shuffle_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e612c0",
   "metadata": {},
   "source": [
    "- Randomizes training order\n",
    "- Prevents the model from learning the **sequence** instead of patterns\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ **Training: `train_model()` Method**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.history = self.model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2e344",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üìä **Key Parameters**\n",
    "- **batch_size=32**: Process 32 images at a time\n",
    "- **epochs=20**: Run through entire dataset 20 times\n",
    "- **validation_data**: Check performance on unseen data each epoch\n",
    "- **callbacks**: Control training behavior\n",
    "\n",
    "### üéØ **Callbacks**\n",
    "\n",
    "**1. EarlyStopping**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4473eb",
   "metadata": {},
   "source": [
    "- **Monitor**: Watch validation loss\n",
    "- **Patience=4**: Stop if no improvement for 4 consecutive epochs\n",
    "- Prevents **overfitting** and **wastes training time**\n",
    "\n",
    "**2. ReduceLROnPlateau**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a39685",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a63bf2",
   "metadata": {},
   "source": [
    "- **If** validation loss plateaus for 2 epochs\n",
    "- **Then** multiply learning rate by 0.5 (reduce to half)\n",
    "- Takes smaller steps when stuck\n",
    "- Minimum learning rate: 0.00001\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ **Evaluation: `evaluate_model()` Method**\n",
    "\n",
    "### üé≤ **Getting Predictions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdabeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = self.model.predict(X_test, verbose=0)\n",
    "y_pred = (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8bb2b",
   "metadata": {},
   "source": [
    "- Model outputs values 0-1 (probability)\n",
    "- **> 0.5 = Pneumonia (1)**, **‚â§ 0.5 = Normal (0)**\n",
    "\n",
    "### üìà **Performance Metrics**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c726711",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "Accuracy = (TP + TN) / Total\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592cd23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example Scenario (100 test images: 50 Normal, 50 Pneumonia)**\n",
    "- **TP=45**: Correctly predicted Pneumonia\n",
    "- **FP=5**: Predicted Pneumonia, actually Normal\n",
    "- **FN=5**: Predicted Normal, actually Pneumonia\n",
    "- **TN=45**: Correctly predicted Normal\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|--------|-------|-----------------|\n",
    "| Accuracy | 90% | Gets 90% of cases right |\n",
    "| Precision | 90% | When predicting Pneumonia, 90% correct |\n",
    "| Recall | 90% | Catches 90% of actual Pneumonia cases |\n",
    "| F1 Score | 90% | Balanced measure of precision & recall |\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ **Real-World Performance** (From Your Training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4ddf0",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "Training Accuracy:   96%  ‚Üê Very high (saw many examples)\n",
    "Validation Accuracy: 87.5% ‚Üê Lower (unseen during training)\n",
    "Test Accuracy:       74%   ‚Üê Actual real-world performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90451602",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**What this tells us:**\n",
    "- ‚úÖ Model learned well (training high)\n",
    "- ‚ö†Ô∏è Some overfitting (validation lower than training)\n",
    "- ‚ùì Lower test accuracy suggests dataset differences\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ **Why This Architecture Works**\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| **Conv2D blocks** | Extract features at multiple scales |\n",
    "| **BatchNormalization** | Stabilize training & faster convergence |\n",
    "| **MaxPooling** | Reduce spatial dimensions, focus on important features |\n",
    "| **Dropout** | Prevent overfitting |\n",
    "| **GlobalAveragePooling** | Combine all feature maps smoothly |\n",
    "| **Dense layers** | Learn complex relationships |\n",
    "| **Sigmoid output** | Convert to probability (0-1) |\n",
    "\n",
    "---\n",
    "\n",
    "## üîü **Complete Training Pipeline**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c139c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Initialize classifier\n",
    "   ‚Üì\n",
    "2. Create CNN model (117 layers total)\n",
    "   ‚Üì\n",
    "3. Load 1341 Normal + 3500 Pneumonia images\n",
    "   ‚Üì\n",
    "4. Train on 4841 images for 20 epochs max\n",
    "   ‚Üì\n",
    "5. Validate on 16 images each epoch\n",
    "   ‚Üì\n",
    "6. Stop early if not improving\n",
    "   ‚Üì\n",
    "7. Evaluate on 200 test images\n",
    "   ‚Üì\n",
    "8. Save model & training plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935d8e7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Key Takeaways**\n",
    "\n",
    "‚úÖ **CNN** learns hierarchical features automatically  \n",
    "‚úÖ **Dropout** prevents memorization (overfitting)  \n",
    "‚úÖ **Batch Normalization** stabilizes training  \n",
    "‚úÖ **Early Stopping** prevents wasting time  \n",
    "‚úÖ **Binary classification** with sigmoid output  \n",
    "‚úÖ **Real medical data** beats synthetic data  \n",
    "\n",
    "Would you like me to explain any specific part in more detail?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
